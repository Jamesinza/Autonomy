<h2>Experiment: Self-Modifying Neural Systems</h2>

<p>
This experiment investigates neural networks that modify their own
connectivity, plasticity rules, and capacity during training.
Rather than treating learning dynamics as fixed, the model learns
when, where, and how to change itself.
</p>

<ul>
  <li>Dynamic neuron growth and pruning</li>
  <li>Learned plasticity rules via meta-controllers</li>
  <li>Homeostatic regulation of activity and weight magnitudes</li>
  <li>Neuromodulated updates driven by reward, novelty, and entropy</li>
  <li>Mixture-of-Experts with independently plastic sub-networks</li>
</ul>

<p>
The goal is not benchmark performance, but to surface failure modes,
stability limits, and emergent behaviors in systems that learn how to learn.
The result is not a clean architecture, but a living system that exposes the cost of autonomy:
</p>

<ul>
  <li>Instability</li>
  <li>Delayed credit assignment</li>
  <li>Emergent failure modes</li>
</ul>

<h3>Why Explore This?</h3>
<p>
Static architectures assume stationary problems.
Biological systems do not.
This work probes whether adaptive structure can outperform
manual design in long-horizon or non-stationary settings.
</p>

<blockquote>I experiment with neural systems that change their own structure and learning rules during training.</blockquote>
